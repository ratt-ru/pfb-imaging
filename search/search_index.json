{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"PFB-Imaging","text":"<p>PFB-Imaging is a radio interferometric imaging suite based on the preconditioned forward-backward algorithm. It's designed for high-performance astronomical data processing with distributed computing capabilities.</p>"},{"location":"#overview","title":"Overview","text":"<p>PFB-Imaging provides a comprehensive suite of tools for processing radio interferometric data, with a focus on:</p> <ul> <li>High-performance computing: Distributed processing using Dask</li> <li>Advanced algorithms: Preconditioned forward-backward optimization</li> <li>Flexible deconvolution: Support for classical and modern sparsity-based methods</li> <li>Scientific accuracy: Built on proven mathematical foundations</li> </ul>"},{"location":"#key-features","title":"Key Features","text":""},{"location":"#performance","title":"\ud83d\ude80 Performance","text":"<ul> <li>Distributed computing with Dask for scalability</li> <li>Memory-efficient chunked processing for large datasets</li> <li>Optimized algorithms using Numba JIT compilation and DUCC0</li> </ul>"},{"location":"#scientific-capabilities","title":"\ud83d\udd2c Scientific Capabilities","text":"<ul> <li>Full Stokes polarization processing</li> <li>Advanced deconvolution algorithms (SARA, Hogbom, Clark)</li> <li>Sparsity regularization with wavelet transforms</li> <li>Preconditioned optimization for faster convergence</li> </ul>"},{"location":"#developer-friendly","title":"\ud83d\udee0\ufe0f Developer-Friendly","text":"<ul> <li>Modular architecture with worker-based processing pipeline</li> <li>Configuration-driven with YAML schemas</li> <li>Comprehensive testing with automated CI/CD</li> <li>Extensive documentation with examples and tutorials</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#installation","title":"Installation","text":"<pre><code># Install from PyPI\npip install pfb-imaging\n\n# Or install from source\ngit clone https://github.com/ratt-ru/pfb-imaging.git\ncd pfb-imaging\npip install -e .\n</code></pre>"},{"location":"#basic-usage","title":"Basic Usage","text":"<pre><code># Initialize measurement set\npfb init --ms my_data.ms --output-filename my_output\n\n# Create dirty image and PSF\npfb grid --output-filename my_output\n\n# Deconvolve using classical methods\npfb kclean --output-filename my_output\n\n# Restore clean components\npfb restore --output-filename my_output\n</code></pre>"},{"location":"#mathematical-foundation","title":"Mathematical Foundation","text":"<p>PFB-Imaging is built on the preconditioned forward-backward algorithm, which solves the optimization problem:</p> \\[ \\min_x \\frac{1}{2} \\|Ax - b\\|^2_2 + \\lambda \\|Wx\\|_1 \\] <p>Where: - \\(A\\) is the measurement operator (gridding + FFT) - \\(x\\) is the image to be reconstructed - \\(b\\) are the observed visibilities - \\(W\\) is a sparsifying transform (wavelets) - \\(\\lambda\\) controls the regularization strength</p> <p>The algorithm alternates between: 1. Forward step: Gradient descent on the data fidelity term 2. Backward step: Proximal operator of the regularization term</p>"},{"location":"#architecture","title":"Architecture","text":"<p>The system follows a modular worker-based pattern where each processing step is a separate CLI command:</p> <pre><code>graph LR\n    A[Measurement Set] --&gt; B[pfb init]\n    B --&gt; C[pfb grid]\n    C --&gt; D[pfb kclean/sara]\n    D --&gt; E[pfb restore]\n    E --&gt; F[FITS Output]</code></pre>"},{"location":"#getting-help","title":"Getting Help","text":"<ul> <li>\ud83d\udcd6 Documentation: https://pfb-imaging.readthedocs.io/</li> <li>\ud83d\udc1b Issues: GitHub Issues</li> <li>\ud83d\udcac Discussions: GitHub Discussions</li> </ul>"},{"location":"#contributing","title":"Contributing","text":"<p>We welcome contributions! Please see our Contributing Guide for details on how to get started.</p>"},{"location":"#citation","title":"Citation","text":"<p>If you use PFB-Imaging in your research, please cite:</p> <pre><code>@software{pfb_imaging,\n  author = {Bester, Landman},\n  title = {PFB-Imaging: Radio interferometric imaging suite},\n  url = {https://github.com/ratt-ru/pfb-imaging},\n  version = {0.0.5},\n  year = {2024}\n}\n</code></pre>"},{"location":"#license","title":"License","text":"<p>PFB-Imaging is licensed under the MIT License. See LICENSE for details.</p>"},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to PFB-Imaging are documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#unreleased","title":"[Unreleased]","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>Comprehensive documentation with MkDocs Material</li> <li>API documentation with mkdocstrings</li> <li>Mathematical notation support with MathJax</li> <li>Performance benchmarking framework</li> <li>GitHub Actions for documentation deployment</li> </ul>"},{"location":"changelog/#changed","title":"Changed","text":"<ul> <li>Updated dependencies to latest versions</li> <li>Improved error handling in workers</li> <li>Enhanced logging system</li> </ul>"},{"location":"changelog/#fixed","title":"Fixed","text":"<ul> <li>Memory leaks in gridding operations</li> <li>Numerical stability in deconvolution</li> <li>Thread safety in parallel processing</li> </ul>"},{"location":"changelog/#005-2024-01-15","title":"[0.0.5] - 2024-01-15","text":""},{"location":"changelog/#added_1","title":"Added","text":"<ul> <li>SARA deconvolution algorithm</li> <li>Wavelet transform support</li> <li>Sparsity regularization</li> <li>Automatic gain control in CLEAN</li> <li>Progress monitoring and logging</li> </ul>"},{"location":"changelog/#changed_1","title":"Changed","text":"<ul> <li>Improved gridding performance with DUCC0</li> <li>Enhanced PSF computation</li> <li>Better memory management for large datasets</li> </ul>"},{"location":"changelog/#fixed_1","title":"Fixed","text":"<ul> <li>Convergence issues in iterative algorithms</li> <li>Coordinate system handling</li> <li>FITS header metadata</li> </ul>"},{"location":"changelog/#004-2023-12-01","title":"[0.0.4] - 2023-12-01","text":""},{"location":"changelog/#added_2","title":"Added","text":"<ul> <li>Preconditioned conjugate gradient solver</li> <li>Multi-frequency synthesis</li> <li>Robust weighting schemes</li> <li>Distributed computing with Dask</li> </ul>"},{"location":"changelog/#changed_2","title":"Changed","text":"<ul> <li>Refactored operator architecture</li> <li>Improved configuration system</li> <li>Enhanced error messages</li> </ul>"},{"location":"changelog/#fixed_2","title":"Fixed","text":"<ul> <li>Gridding artifacts near image boundaries</li> <li>Memory usage in large-scale processing</li> <li>Numerical precision in FFT operations</li> </ul>"},{"location":"changelog/#003-2023-10-15","title":"[0.0.3] - 2023-10-15","text":""},{"location":"changelog/#added_3","title":"Added","text":"<ul> <li>Classical CLEAN algorithms (Hogbom, Clark)</li> <li>PSF and beam model support</li> <li>FITS I/O functionality</li> <li>Configuration file support</li> </ul>"},{"location":"changelog/#changed_3","title":"Changed","text":"<ul> <li>Modular worker architecture</li> <li>Improved CLI interface</li> <li>Better test coverage</li> </ul>"},{"location":"changelog/#fixed_3","title":"Fixed","text":"<ul> <li>Threading issues in parallel processing</li> <li>Coordinate transformations</li> <li>Memory allocation in chunked arrays</li> </ul>"},{"location":"changelog/#002-2023-09-01","title":"[0.0.2] - 2023-09-01","text":""},{"location":"changelog/#added_4","title":"Added","text":"<ul> <li>Basic gridding and degridding</li> <li>Measurement set parsing</li> <li>Xarray dataset support</li> <li>Initial CLI framework</li> </ul>"},{"location":"changelog/#changed_4","title":"Changed","text":"<ul> <li>Switched to Poetry for dependency management</li> <li>Improved project structure</li> <li>Enhanced documentation</li> </ul>"},{"location":"changelog/#fixed_4","title":"Fixed","text":"<ul> <li>Installation issues on different platforms</li> <li>Dependency version conflicts</li> <li>Basic functionality bugs</li> </ul>"},{"location":"changelog/#001-2023-08-01","title":"[0.0.1] - 2023-08-01","text":""},{"location":"changelog/#added_5","title":"Added","text":"<ul> <li>Initial project structure</li> <li>Basic measurement set reading</li> <li>Prototype imaging pipeline</li> <li>Core mathematical operators</li> </ul>"},{"location":"changelog/#changed_5","title":"Changed","text":"<ul> <li>N/A (initial release)</li> </ul>"},{"location":"changelog/#fixed_5","title":"Fixed","text":"<ul> <li>N/A (initial release)</li> </ul>"},{"location":"changelog/#release-notes-template","title":"Release Notes Template","text":"<p>For maintainers: Use this template for new releases:</p> <pre><code>## [X.Y.Z] - YYYY-MM-DD\n\n### Added\n- New feature 1\n- New feature 2\n\n### Changed\n- Changed feature 1\n- Changed feature 2\n\n### Deprecated\n- Deprecated feature 1\n\n### Removed\n- Removed feature 1\n\n### Fixed\n- Bug fix 1\n- Bug fix 2\n\n### Security\n- Security fix 1\n</code></pre>"},{"location":"changelog/#migration-guides","title":"Migration Guides","text":""},{"location":"changelog/#upgrading-from-004-to-005","title":"Upgrading from 0.0.4 to 0.0.5","text":"<p>Breaking Changes: - Configuration schema changes in <code>sara.yaml</code> - New required dependencies (PyWavelets)</p> <p>Migration Steps: 1. Update configuration files:    <pre><code># Old format\nregularization: 0.1\n\n# New format\ngamma: 0.1\nl1_reweight_from: 100\n</code></pre></p> <ol> <li> <p>Install new dependencies:    <pre><code>pip install PyWavelets&gt;=1.7.0\n</code></pre></p> </li> <li> <p>Update function calls:    <pre><code># Old API\nsara_clean(image, psf, regularization=0.1)\n\n# New API\nsara_clean(image, psf, gamma=0.1, l1_reweight_from=100)\n</code></pre></p> </li> </ol>"},{"location":"changelog/#upgrading-from-003-to-004","title":"Upgrading from 0.0.3 to 0.0.4","text":"<p>Breaking Changes: - New operator architecture - Modified CLI argument names</p> <p>Migration Steps: 1. Update CLI commands:    <pre><code># Old command\npfb clean --niter 1000 --gain 0.1\n\n# New command\npfb kclean --niter 1000 --gain 0.1\n</code></pre></p> <ol> <li>Update Python API:    <pre><code># Old API\nfrom pfb.clean import hogbom_clean\n\n# New API\nfrom pfb.deconv.hogbom import HogbomClean\n</code></pre></li> </ol>"},{"location":"changelog/#development-changelog","title":"Development Changelog","text":""},{"location":"changelog/#code-quality-improvements","title":"Code Quality Improvements","text":"<ul> <li>2024-01-15: Added type hints throughout codebase</li> <li>2023-12-01: Improved test coverage to 85%</li> <li>2023-10-15: Added pre-commit hooks for code formatting</li> <li>2023-09-01: Migrated to Poetry for dependency management</li> </ul>"},{"location":"changelog/#performance-improvements","title":"Performance Improvements","text":"<ul> <li>2024-01-15: 30% speedup in gridding operations</li> <li>2023-12-01: Memory usage reduced by 40% for large datasets</li> <li>2023-10-15: Parallel processing efficiency improved</li> </ul>"},{"location":"changelog/#documentation-updates","title":"Documentation Updates","text":"<ul> <li>2024-01-15: Comprehensive documentation with MkDocs</li> <li>2023-12-01: Added mathematical background documentation</li> <li>2023-10-15: Improved API documentation with examples</li> <li>2023-09-01: Added user guide and tutorials</li> </ul>"},{"location":"changelog/#known-issues","title":"Known Issues","text":""},{"location":"changelog/#current-limitations","title":"Current Limitations","text":"<ul> <li>Memory usage can be high for very large datasets (&gt;100GB)</li> <li>GPU acceleration not yet implemented</li> <li>Limited support for irregular arrays</li> </ul>"},{"location":"changelog/#workarounds","title":"Workarounds","text":"<ul> <li>Use chunked processing for large datasets</li> <li>Increase swap space for memory-intensive operations</li> <li>Use distributed computing for scalability</li> </ul>"},{"location":"changelog/#future-roadmap","title":"Future Roadmap","text":""},{"location":"changelog/#planned-features","title":"Planned Features","text":"<ul> <li>GPU acceleration with JAX</li> <li>Advanced deconvolution algorithms</li> <li>Real-time processing capabilities</li> <li>Cloud computing integration</li> </ul>"},{"location":"changelog/#performance-targets","title":"Performance Targets","text":"<ul> <li>50% reduction in memory usage</li> <li>2x speedup in gridding operations</li> <li>Support for datasets &gt;1TB</li> </ul>"},{"location":"changelog/#api-stability","title":"API Stability","text":"<ul> <li>Major API changes only in major versions</li> <li>Deprecation warnings for 2 minor versions</li> <li>Backward compatibility maintained when possible</li> </ul>"},{"location":"configuration/","title":"Configuration","text":"<p>PFB-Imaging uses a flexible configuration system based on YAML schemas. Each worker has its own configuration schema that automatically generates CLI parameters.</p>"},{"location":"configuration/#configuration-methods","title":"Configuration Methods","text":""},{"location":"configuration/#1-command-line-arguments","title":"1. Command Line Arguments","text":"<p>The simplest way to configure PFB-Imaging:</p> <pre><code>pfb kclean --niter 1000 --threshold 0.01 --gain 0.1\n</code></pre>"},{"location":"configuration/#2-configuration-files","title":"2. Configuration Files","text":"<p>Create a YAML configuration file:</p> <pre><code># config.yaml\nniter: 1000\nthreshold: 0.01\ngain: 0.1\nnworkers: 4\noutput_filename: my_image\n</code></pre> <p>Use with:</p> <pre><code>pfb kclean --config config.yaml\n</code></pre>"},{"location":"configuration/#3-environment-variables","title":"3. Environment Variables","text":"<p>Set configuration via environment variables:</p> <pre><code>export PFB_NITER=1000\nexport PFB_THRESHOLD=0.01\npfb kclean --output-filename my_image\n</code></pre>"},{"location":"configuration/#common-configuration-options","title":"Common Configuration Options","text":""},{"location":"configuration/#global-options","title":"Global Options","text":"<p>These options are available for all workers:</p> <pre><code># Processing\nnworkers: 4                    # Number of parallel workers\nnthreads_per_worker: 2         # Threads per worker\nscheduler: threads             # Dask scheduler type\n\n# Output\noutput_filename: my_image      # Base name for outputs\nfits_output_folder: outputs/   # Directory for FITS files\nlog_level: INFO               # Logging level\n\n# Performance\nchunks: 4096                  # Chunk size for arrays\nmemory_limit: 8GB             # Memory limit per worker\n</code></pre>"},{"location":"configuration/#gridding-options","title":"Gridding Options","text":"<p>Configure the gridding process:</p> <pre><code># Image parameters\nnx: 2048                      # Image width\nny: 2048                      # Image height\ncell_size: 2.0                # Cell size in arcseconds\nfield_of_view: 2.0            # Field of view in degrees\n\n# Gridding\nepsilon: 1e-7                 # Gridding accuracy\ndo_psf: true                  # Compute PSF\ndo_residual: true             # Compute residual\ndo_dirty: true                # Compute dirty image\n\n# Weighting\nrobust: 0.0                   # Robust weighting parameter\nnatural: false                # Use natural weighting\n</code></pre>"},{"location":"configuration/#deconvolution-options","title":"Deconvolution Options","text":""},{"location":"configuration/#classical-clean-kclean","title":"Classical CLEAN (kclean)","text":"<pre><code># Basic parameters\nniter: 1000                   # Maximum iterations\nthreshold: 0.01               # Cleaning threshold\ngain: 0.1                     # CLEAN gain\n\n# Advanced\ncyclefactor: 2.5              # Major cycle trigger\nnchan: 1                      # Number of channels\nnband: 1                      # Number of bands\n</code></pre>"},{"location":"configuration/#sara-deconvolution","title":"SARA Deconvolution","text":"<pre><code># Regularization\ngamma: 0.1                    # Regularization parameter\nl1_reweight_from: 100         # Start reweighting iteration\nreweight_alpha: 0.8           # Reweighting parameter\n\n# Constraints\npositivity: true              # Enforce positivity\nflux_constraint: false        # Enforce flux constraint\npeak_constraint: false        # Enforce peak constraint\n\n# Optimization\ntol: 1e-5                     # Convergence tolerance\nmaxit: 500                    # Maximum iterations\n</code></pre>"},{"location":"configuration/#schema-based-configuration","title":"Schema-Based Configuration","text":"<p>PFB-Imaging uses YAML schemas to define configuration parameters. Schemas are located in <code>pfb/parser/</code> and automatically generate CLI interfaces.</p>"},{"location":"configuration/#example-schema","title":"Example Schema","text":"<pre><code># pfb/parser/kclean.yaml\nniter:\n  dtype: int\n  default: 1000\n  help: Maximum number of iterations\n\nthreshold:\n  dtype: float\n  default: 0.01\n  help: Cleaning threshold as fraction of peak\n\ngain:\n  dtype: float\n  default: 0.1\n  help: CLEAN gain factor\n</code></pre>"},{"location":"configuration/#custom-configuration","title":"Custom Configuration","text":"<p>Create custom configurations for specific use cases:</p> <pre><code># high_dynamic_range.yaml\nniter: 10000\nthreshold: 0.001\ngain: 0.05\ncyclefactor: 1.5\n</code></pre> <pre><code># fast_processing.yaml\nniter: 500\nthreshold: 0.05\ngain: 0.2\nnworkers: 8\n</code></pre>"},{"location":"configuration/#environment-specific-configuration","title":"Environment-Specific Configuration","text":""},{"location":"configuration/#development","title":"Development","text":"<pre><code># dev_config.yaml\nlog_level: DEBUG\nnworkers: 1\nchunks: 1024\noutput_filename: test_image\n</code></pre>"},{"location":"configuration/#production","title":"Production","text":"<pre><code># prod_config.yaml\nlog_level: INFO\nnworkers: 16\nnthreads_per_worker: 2\nmemory_limit: 16GB\nchunks: 8192\n</code></pre>"},{"location":"configuration/#cluster-computing","title":"Cluster Computing","text":"<pre><code># cluster_config.yaml\nscheduler: distributed\nnworkers: 32\nmemory_limit: 32GB\nchunks: 16384\n</code></pre>"},{"location":"configuration/#performance-tuning","title":"Performance Tuning","text":""},{"location":"configuration/#memory-management","title":"Memory Management","text":"<pre><code># Memory optimization\nchunks: 2048                  # Smaller chunks for less memory\nmemory_limit: 4GB             # Per-worker memory limit\nspill_to_disk: true          # Enable disk spilling\n</code></pre>"},{"location":"configuration/#cpu-optimization","title":"CPU Optimization","text":"<pre><code># CPU optimization\nnthreads_per_worker: 4        # Match CPU cores\nscheduler: threads            # Use threaded scheduler\n</code></pre>"},{"location":"configuration/#io-optimization","title":"I/O Optimization","text":"<pre><code># I/O optimization\nrechunk: true                 # Rechunk arrays for I/O\ncompression: lz4              # Use compression\n</code></pre>"},{"location":"configuration/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"configuration/#dask-configuration","title":"Dask Configuration","text":"<p>Create a Dask configuration file:</p> <pre><code># dask.yaml\ndistributed:\n  worker:\n    memory:\n      target: 0.8\n      spill: 0.9\n      pause: 0.95\n      terminate: 0.98\n  scheduler:\n    allowed-failures: 10\n    work-stealing: true\n</code></pre> <p>Set with:</p> <pre><code>export DASK_CONFIG=/path/to/dask.yaml\n</code></pre>"},{"location":"configuration/#logging-configuration","title":"Logging Configuration","text":"<pre><code># logging.yaml\nversion: 1\nformatters:\n  standard:\n    format: '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\nhandlers:\n  default:\n    class: logging.StreamHandler\n    formatter: standard\n    level: INFO\nloggers:\n  pfb:\n    level: DEBUG\n    handlers: [default]\n</code></pre>"},{"location":"configuration/#configuration-validation","title":"Configuration Validation","text":"<p>PFB-Imaging validates configuration parameters:</p> <pre><code># Check configuration\npfb kclean --config config.yaml --validate-only\n\n# Show default configuration\npfb kclean --show-config\n</code></pre>"},{"location":"configuration/#best-practices","title":"Best Practices","text":""},{"location":"configuration/#1-use-version-control","title":"1. Use Version Control","text":"<p>Store configuration files in version control:</p> <pre><code>git add config.yaml\ngit commit -m \"Add imaging configuration\"\n</code></pre>"},{"location":"configuration/#2-environment-specific-configs","title":"2. Environment-Specific Configs","text":"<p>Maintain separate configs for different environments:</p> <pre><code>configs/\n\u251c\u2500\u2500 development.yaml\n\u251c\u2500\u2500 staging.yaml\n\u2514\u2500\u2500 production.yaml\n</code></pre>"},{"location":"configuration/#3-parameter-sweeps","title":"3. Parameter Sweeps","text":"<p>Use configuration files for parameter studies:</p> <pre><code># Different regularization parameters\nfor gamma in 0.01 0.1 1.0; do\n    sed \"s/gamma: .*/gamma: $gamma/\" config.yaml &gt; config_$gamma.yaml\n    pfb sara --config config_$gamma.yaml --output-filename image_$gamma\ndone\n</code></pre>"},{"location":"configuration/#4-documentation","title":"4. Documentation","text":"<p>Document your configuration choices:</p> <pre><code># config.yaml\n# Configuration for high dynamic range imaging\n# Optimized for point source recovery\n\nniter: 10000      # High iteration count for deep cleaning\nthreshold: 0.001  # Low threshold for faint sources\ngain: 0.05        # Conservative gain for stability\n</code></pre>"},{"location":"configuration/#troubleshooting-configuration","title":"Troubleshooting Configuration","text":""},{"location":"configuration/#common-issues","title":"Common Issues","text":""},{"location":"configuration/#invalid-parameters","title":"Invalid Parameters","text":"<pre><code># Check parameter validity\npfb kclean --config config.yaml --validate-only\n</code></pre>"},{"location":"configuration/#performance-issues","title":"Performance Issues","text":"<pre><code># Profile configuration\npfb kclean --config config.yaml --profile\n</code></pre>"},{"location":"configuration/#memory-problems","title":"Memory Problems","text":"<pre><code># Reduce memory usage\nchunks: 1024\nmemory_limit: 2GB\nspill_to_disk: true\n</code></pre>"},{"location":"configuration/#configuration-debugging","title":"Configuration Debugging","text":"<pre><code># Show effective configuration\npfb kclean --config config.yaml --show-effective-config\n\n# Dry run\npfb kclean --config config.yaml --dry-run\n</code></pre>"},{"location":"contributing/","title":"Contributing to PFB-Imaging","text":"<p>Thank you for your interest in contributing to PFB-Imaging! This guide will help you get started with development and contributing to the project.</p>"},{"location":"contributing/#getting-started","title":"Getting Started","text":""},{"location":"contributing/#development-environment","title":"Development Environment","text":"<ol> <li> <p>Fork and clone the repository:    <pre><code>git clone https://github.com/YOUR_USERNAME/pfb-imaging.git\ncd pfb-imaging\n</code></pre></p> </li> <li> <p>Install in development mode:    <pre><code>poetry install --with docs\n</code></pre></p> </li> <li> <p>Install pre-commit hooks:    <pre><code>pre-commit install\n</code></pre></p> </li> </ol>"},{"location":"contributing/#development-dependencies","title":"Development Dependencies","text":"<p>Install additional development tools:</p> <pre><code>poetry install --with dev,docs,test\n</code></pre> <p>This includes: - Testing frameworks (pytest, pytest-cov) - Code formatting (black, isort) - Linting (flake8, mypy) - Documentation tools (mkdocs, mkdocs-material)</p>"},{"location":"contributing/#development-workflow","title":"Development Workflow","text":""},{"location":"contributing/#1-create-a-feature-branch","title":"1. Create a Feature Branch","text":"<pre><code>git checkout -b feature/your-feature-name\n</code></pre>"},{"location":"contributing/#2-make-your-changes","title":"2. Make Your Changes","text":"<p>Follow the coding standards and patterns described below.</p>"},{"location":"contributing/#3-run-tests","title":"3. Run Tests","text":"<pre><code># Run all tests\npoetry run pytest -v\n\n# Run specific test file\npoetry run pytest -v tests/test_beam.py\n\n# Run with coverage\npoetry run pytest --cov=pfb tests/\n</code></pre>"},{"location":"contributing/#4-format-and-lint-code","title":"4. Format and Lint Code","text":"<pre><code># Format code\npoetry run black pfb/ tests/\npoetry run isort pfb/ tests/\n\n# Lint code\npoetry run flake8 pfb/ tests/\npoetry run mypy pfb/\n</code></pre>"},{"location":"contributing/#5-submit-pull-request","title":"5. Submit Pull Request","text":"<ol> <li>Push your changes to your fork</li> <li>Create a pull request against the main repository</li> <li>Fill out the pull request template</li> <li>Wait for review and address feedback</li> </ol>"},{"location":"contributing/#coding-standards","title":"Coding Standards","text":""},{"location":"contributing/#python-style","title":"Python Style","text":"<ul> <li>PEP 8: Follow Python style guidelines</li> <li>Type hints: Use type annotations for all functions</li> <li>Docstrings: Use NumPy-style docstrings</li> <li>Black: Use Black for code formatting</li> <li>isort: Use isort for import sorting</li> </ul>"},{"location":"contributing/#example-function","title":"Example Function","text":"<pre><code>import numpy as np\nfrom typing import Tuple, Optional\n\ndef gridding_operator(\n    visibilities: np.ndarray,\n    uvw: np.ndarray,\n    weights: np.ndarray,\n    nx: int,\n    ny: int,\n    cell_size: float,\n    epsilon: float = 1e-7\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Grid visibilities onto a regular grid.\n\n    Parameters\n    ----------\n    visibilities : np.ndarray\n        Complex visibility data with shape (nvis,)\n    uvw : np.ndarray\n        UVW coordinates with shape (nvis, 3)\n    weights : np.ndarray\n        Visibility weights with shape (nvis,)\n    nx : int\n        Number of pixels in x direction\n    ny : int\n        Number of pixels in y direction\n    cell_size : float\n        Cell size in arcseconds\n    epsilon : float, optional\n        Gridding accuracy, by default 1e-7\n\n    Returns\n    -------\n    grid : np.ndarray\n        Gridded visibilities with shape (nx, ny)\n    weights_grid : np.ndarray\n        Gridded weights with shape (nx, ny)\n\n    Examples\n    --------\n    &gt;&gt;&gt; vis = np.random.complex128(1000)\n    &gt;&gt;&gt; uvw = np.random.random((1000, 3))\n    &gt;&gt;&gt; weights = np.ones(1000)\n    &gt;&gt;&gt; grid, wgrid = gridding_operator(vis, uvw, weights, 256, 256, 2.0)\n    \"\"\"\n    # Implementation here\n    pass\n</code></pre>"},{"location":"contributing/#mathematical-operators","title":"Mathematical Operators","text":"<p>Implement operators as callable classes:</p> <pre><code>class GriddingOperator:\n    \"\"\"Gridding operator for radio interferometry.\"\"\"\n\n    def __init__(self, uvw: np.ndarray, nx: int, ny: int, cell_size: float):\n        \"\"\"\n        Initialize gridding operator.\n\n        Parameters\n        ----------\n        uvw : np.ndarray\n            UVW coordinates\n        nx, ny : int\n            Image dimensions\n        cell_size : float\n            Cell size in arcseconds\n        \"\"\"\n        self.uvw = uvw\n        self.nx = nx\n        self.ny = ny\n        self.cell_size = cell_size\n        self._setup_kernel()\n\n    def __call__(self, visibilities: np.ndarray) -&gt; np.ndarray:\n        \"\"\"Apply gridding operator (forward operation).\"\"\"\n        return self._grid(visibilities)\n\n    def adjoint(self, image: np.ndarray) -&gt; np.ndarray:\n        \"\"\"Apply adjoint gridding operator (degridding).\"\"\"\n        return self._degrid(image)\n\n    def _setup_kernel(self) -&gt; None:\n        \"\"\"Setup gridding kernel.\"\"\"\n        # Implementation\n        pass\n\n    def _grid(self, visibilities: np.ndarray) -&gt; np.ndarray:\n        \"\"\"Grid visibilities.\"\"\"\n        # Implementation\n        pass\n\n    def _degrid(self, image: np.ndarray) -&gt; np.ndarray:\n        \"\"\"Degrid image.\"\"\"\n        # Implementation\n        pass\n</code></pre>"},{"location":"contributing/#testing","title":"Testing","text":""},{"location":"contributing/#test-structure","title":"Test Structure","text":"<p>Tests are organized by module:</p> <pre><code>tests/\n\u251c\u2500\u2500 test_beam.py          # Beam model tests\n\u251c\u2500\u2500 test_gridding.py      # Gridding operator tests\n\u251c\u2500\u2500 test_deconv.py        # Deconvolution tests\n\u251c\u2500\u2500 test_operators.py     # Mathematical operator tests\n\u251c\u2500\u2500 test_utils.py         # Utility function tests\n\u2514\u2500\u2500 data/                 # Test data\n</code></pre>"},{"location":"contributing/#writing-tests","title":"Writing Tests","text":"<p>Use pytest and parametrize tests:</p> <pre><code>import pytest\nimport numpy as np\nfrom pfb.operators.gridding import GriddingOperator\n\nclass TestGriddingOperator:\n    \"\"\"Test gridding operator.\"\"\"\n\n    @pytest.fixture\n    def sample_data(self):\n        \"\"\"Create sample test data.\"\"\"\n        nvis = 1000\n        uvw = np.random.random((nvis, 3))\n        visibilities = np.random.complex128(nvis)\n        weights = np.ones(nvis)\n        return uvw, visibilities, weights\n\n    @pytest.mark.parametrize(\"nx,ny\", [(256, 256), (512, 512)])\n    def test_gridding_shapes(self, sample_data, nx, ny):\n        \"\"\"Test gridding produces correct shapes.\"\"\"\n        uvw, vis, weights = sample_data\n\n        op = GriddingOperator(uvw, nx, ny, cell_size=2.0)\n        grid = op(vis)\n\n        assert grid.shape == (nx, ny)\n        assert grid.dtype == np.complex128\n\n    def test_adjoint_property(self, sample_data):\n        \"\"\"Test adjoint property: &lt;Ax, y&gt; = &lt;x, A^H y&gt;.\"\"\"\n        uvw, vis, weights = sample_data\n\n        op = GriddingOperator(uvw, 256, 256, cell_size=2.0)\n\n        # Create test vectors\n        x = np.random.complex128(len(vis))\n        y = np.random.complex128((256, 256))\n\n        # Test adjoint property\n        lhs = np.vdot(op(x), y)\n        rhs = np.vdot(x, op.adjoint(y))\n\n        np.testing.assert_allclose(lhs, rhs, rtol=1e-10)\n</code></pre>"},{"location":"contributing/#test-data","title":"Test Data","text":"<p>Large test data is automatically downloaded:</p> <pre><code># conftest.py handles automatic download\n@pytest.fixture(scope=\"session\")\ndef ms_data():\n    \"\"\"Download and return measurement set data.\"\"\"\n    # Automatically downloads test data\n    return download_test_data(\"test_ms.tar.gz\")\n</code></pre>"},{"location":"contributing/#documentation","title":"Documentation","text":""},{"location":"contributing/#docstring-standards","title":"Docstring Standards","text":"<p>Use NumPy-style docstrings:</p> <pre><code>def my_function(param1: int, param2: float) -&gt; bool:\n    \"\"\"\n    Brief description of the function.\n\n    Longer description if needed. Can include mathematical\n    notation using LaTeX:\n\n    .. math::\n        x = \\arg\\min_x \\|Ax - b\\|^2_2 + \\lambda \\|x\\|_1\n\n    Parameters\n    ----------\n    param1 : int\n        Description of param1\n    param2 : float\n        Description of param2\n\n    Returns\n    -------\n    bool\n        Description of return value\n\n    Raises\n    ------\n    ValueError\n        If param1 is negative\n    TypeError\n        If param2 is not a float\n\n    Examples\n    --------\n    &gt;&gt;&gt; result = my_function(10, 3.14)\n    &gt;&gt;&gt; print(result)\n    True\n\n    See Also\n    --------\n    related_function : Related functionality\n    \"\"\"\n    pass\n</code></pre>"},{"location":"contributing/#building-documentation","title":"Building Documentation","text":"<pre><code># Build documentation\npoetry run mkdocs build\n\n# Serve documentation locally\npoetry run mkdocs serve\n\n# Deploy to GitHub Pages\npoetry run mkdocs gh-deploy\n</code></pre>"},{"location":"contributing/#project-structure","title":"Project Structure","text":"<p>Understanding the codebase structure:</p> <pre><code>pfb/\n\u251c\u2500\u2500 workers/              # CLI workers (main entry points)\n\u2502   \u251c\u2500\u2500 init.py          # Initialize measurement sets\n\u2502   \u251c\u2500\u2500 grid.py          # Gridding worker\n\u2502   \u251c\u2500\u2500 kclean.py        # Classical deconvolution\n\u2502   \u2514\u2500\u2500 sara.py          # SARA deconvolution\n\u251c\u2500\u2500 operators/           # Mathematical operators\n\u2502   \u251c\u2500\u2500 gridding.py      # Gridding operators\n\u2502   \u251c\u2500\u2500 psf.py           # PSF operators\n\u2502   \u2514\u2500\u2500 fft.py           # FFT operators\n\u251c\u2500\u2500 opt/                 # Optimization algorithms\n\u2502   \u251c\u2500\u2500 pcg.py           # Preconditioned conjugate gradient\n\u2502   \u2514\u2500\u2500 fista.py         # FISTA algorithm\n\u251c\u2500\u2500 deconv/              # Deconvolution algorithms\n\u2502   \u251c\u2500\u2500 hogbom.py        # Hogbom CLEAN\n\u2502   \u2514\u2500\u2500 sara.py          # SARA algorithm\n\u251c\u2500\u2500 utils/               # Utility functions\n\u2502   \u251c\u2500\u2500 fits.py          # FITS I/O\n\u2502   \u2514\u2500\u2500 naming.py        # File naming conventions\n\u2514\u2500\u2500 parser/              # Configuration schemas\n    \u251c\u2500\u2500 init.yaml        # Init worker schema\n    \u2514\u2500\u2500 grid.yaml        # Grid worker schema\n</code></pre>"},{"location":"contributing/#performance-considerations","title":"Performance Considerations","text":""},{"location":"contributing/#memory-management","title":"Memory Management","text":"<ul> <li>Use chunked arrays for large datasets</li> <li>Implement memory-efficient algorithms</li> <li>Profile memory usage with <code>memory_profiler</code></li> </ul>"},{"location":"contributing/#parallel-processing","title":"Parallel Processing","text":"<ul> <li>Use Dask for distributed computing</li> <li>Implement thread-safe operations</li> <li>Consider NUMA topology for performance</li> </ul>"},{"location":"contributing/#numerical-stability","title":"Numerical Stability","text":"<ul> <li>Use appropriate data types (float64 for coordinates)</li> <li>Handle edge cases in algorithms</li> <li>Validate numerical accuracy in tests</li> </ul>"},{"location":"contributing/#review-process","title":"Review Process","text":""},{"location":"contributing/#pull-request-checklist","title":"Pull Request Checklist","text":"<ul> <li> Code follows style guidelines</li> <li> Tests pass and cover new functionality</li> <li> Documentation is updated</li> <li> Performance impact is considered</li> <li> Backwards compatibility is maintained</li> </ul>"},{"location":"contributing/#code-review","title":"Code Review","text":"<ul> <li>Focus on correctness and clarity</li> <li>Consider performance implications</li> <li>Ensure proper error handling</li> <li>Verify test coverage</li> </ul>"},{"location":"contributing/#getting-help","title":"Getting Help","text":"<ul> <li>Issues: Report bugs and request features on GitHub</li> <li>Discussions: Ask questions in GitHub Discussions</li> <li>Chat: Join our development chat (link in README)</li> </ul>"},{"location":"contributing/#recognition","title":"Recognition","text":"<p>Contributors are recognized in: - AUTHORS file - Release notes - Documentation acknowledgments</p> <p>Thank you for contributing to PFB-Imaging!</p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#requirements","title":"Requirements","text":"<p>PFB-Imaging requires Python 3.10 or later and is tested on Linux systems. The package depends on several scientific Python libraries and specialized radio astronomy tools.</p>"},{"location":"installation/#system-requirements","title":"System Requirements","text":"<ul> <li>Python: 3.10, 3.11, or 3.12</li> <li>Operating System: Linux (Ubuntu 20.04+, CentOS 8+, or similar)</li> <li>Memory: At least 8GB RAM (16GB+ recommended for large datasets)</li> <li>Storage: Fast SSD recommended for optimal performance</li> </ul>"},{"location":"installation/#installation-methods","title":"Installation Methods","text":""},{"location":"installation/#1-pypi-installation-recommended","title":"1. PyPI Installation (Recommended)","text":"<p>The easiest way to install PFB-Imaging is from PyPI:</p> <pre><code>pip install pfb-imaging\n</code></pre>"},{"location":"installation/#2-development-installation","title":"2. Development Installation","text":"<p>For development or to get the latest features:</p> <pre><code>git clone https://github.com/ratt-ru/pfb-imaging.git\ncd pfb-imaging\npip install -e .\n</code></pre>"},{"location":"installation/#3-poetry-installation-advanced","title":"3. Poetry Installation (Advanced)","text":"<p>If you prefer using Poetry for dependency management:</p> <pre><code>git clone https://github.com/ratt-ru/pfb-imaging.git\ncd pfb-imaging\npoetry install\n</code></pre>"},{"location":"installation/#performance-optimization","title":"Performance Optimization","text":""},{"location":"installation/#ducc0-optimization","title":"DUCC0 Optimization","text":"<p>For maximum performance, install DUCC0 from source:</p> <pre><code>git clone https://gitlab.mpcdf.mpg.de/mtr/ducc.git\npip install -e ducc\n</code></pre> <p>This provides optimized FFT and gridding operations.</p>"},{"location":"installation/#jax-backend","title":"JAX Backend","text":"<p>PFB-Imaging uses JAX for automatic differentiation. For GPU acceleration:</p> <pre><code># For CUDA support\npip install jax[cuda] -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n\n# For TPU support\npip install jax[tpu] -f https://storage.googleapis.com/jax-releases/libtpu_releases.html\n</code></pre>"},{"location":"installation/#casa-measures-data","title":"CASA Measures Data","text":"<p>PFB-Imaging requires CASA measures data for coordinate transformations. This is automatically downloaded during the first run, but you can pre-install it:</p> <pre><code>mkdir -p ~/measures\ncurl ftp://ftp.astron.nl/outgoing/Measures/WSRT_Measures.ztar | tar xvzf - -C ~/measures\necho \"measures.directory: ~/measures\" &gt; ~/.casarc\n</code></pre>"},{"location":"installation/#verification","title":"Verification","text":"<p>Verify your installation by running:</p> <pre><code>pfb --help\n</code></pre> <p>You should see the PFB-Imaging command-line interface with available workers.</p>"},{"location":"installation/#docker-installation","title":"Docker Installation","text":"<p>For containerized deployment:</p> <pre><code># Build Docker image\ndocker build -t pfb-imaging .\n\n# Run with data mounted\ndocker run -v /path/to/data:/data pfb-imaging pfb init --ms /data/my_data.ms\n</code></pre>"},{"location":"installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"installation/#common-issues","title":"Common Issues","text":""},{"location":"installation/#import-errors","title":"Import Errors","text":"<p>If you encounter import errors, ensure all dependencies are installed:</p> <pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"installation/#memory-issues","title":"Memory Issues","text":"<p>For large datasets, increase memory limits:</p> <pre><code>export NUMBA_CACHE_DIR=/tmp/numba-cache\nexport OMP_NUM_THREADS=4\n</code></pre>"},{"location":"installation/#performance-issues","title":"Performance Issues","text":"<ol> <li>Use SSD storage for intermediate files</li> <li>Adjust chunk sizes in configuration</li> <li>Increase number of workers for parallel processing</li> </ol> <pre><code>pfb grid --nworkers 8 --nthreads-per-worker 2\n</code></pre>"},{"location":"installation/#environment-variables","title":"Environment Variables","text":"<p>Configure PFB-Imaging behavior with environment variables:</p> <pre><code># Numba cache directory\nexport NUMBA_CACHE_DIR=/tmp/numba-cache\n\n# OpenMP thread count\nexport OMP_NUM_THREADS=4\n\n# Dask configuration\nexport DASK_CONFIG=/path/to/dask.yaml\n</code></pre>"},{"location":"installation/#dependencies","title":"Dependencies","text":""},{"location":"installation/#core-dependencies","title":"Core Dependencies","text":"<ul> <li>NumPy: Numerical computing</li> <li>SciPy: Scientific computing</li> <li>Dask: Distributed computing</li> <li>Xarray: Labeled arrays</li> <li>JAX: Automatic differentiation</li> </ul>"},{"location":"installation/#radio-astronomy-dependencies","title":"Radio Astronomy Dependencies","text":"<ul> <li>codex-africanus: Radio astronomy algorithms</li> <li>dask-ms: Measurement set I/O</li> <li>katbeam: Beam models</li> <li>python-casacore: CASA table access</li> </ul>"},{"location":"installation/#optional-dependencies","title":"Optional Dependencies","text":"<ul> <li>matplotlib: Plotting</li> <li>bokeh: Interactive visualization</li> <li>jupyter: Notebook support</li> </ul>"},{"location":"installation/#next-steps","title":"Next Steps","text":"<p>After installation, check out the Quick Start guide to begin processing your data.</p>"},{"location":"quickstart/","title":"Quick Start","text":"<p>This guide will walk you through your first PFB-Imaging workflow, from raw measurement set to final image.</p>"},{"location":"quickstart/#prerequisites","title":"Prerequisites","text":"<p>Ensure you have: - PFB-Imaging installed (Installation Guide) - A measurement set (MS) file - Basic familiarity with radio interferometry concepts</p>"},{"location":"quickstart/#basic-workflow","title":"Basic Workflow","text":"<p>The PFB-Imaging pipeline follows a sequential workflow:</p> <pre><code>graph LR\n    A[MS File] --&gt; B[pfb init]\n    B --&gt; C[XDS Files]\n    C --&gt; D[pfb grid]\n    D --&gt; E[DDS Files]\n    E --&gt; F[pfb kclean]\n    F --&gt; G[pfb restore]\n    G --&gt; H[FITS Image]</code></pre>"},{"location":"quickstart/#step-1-initialize-data","title":"Step 1: Initialize Data","text":"<p>Convert your measurement set to PFB-Imaging format:</p> <pre><code>pfb init --ms my_data.ms --output-filename my_output\n</code></pre> <p>This creates xarray datasets (<code>.xds</code> files) containing: - Visibility data - UVW coordinates - Antenna information - Observation metadata</p>"},{"location":"quickstart/#step-2-grid-visibilities","title":"Step 2: Grid Visibilities","text":"<p>Create the dirty image, PSF, and weights:</p> <pre><code>pfb grid --output-filename my_output\n</code></pre> <p>This produces: - <code>my_output_dirty.dds</code>: Dirty image - <code>my_output_psf.dds</code>: Point spread function - <code>my_output_psfhat.dds</code>: PSF in Fourier domain - <code>my_output_residual.dds</code>: Residual visibilities</p>"},{"location":"quickstart/#step-3-deconvolve-classical","title":"Step 3: Deconvolve (Classical)","text":"<p>Apply classical deconvolution using Hogbom CLEAN:</p> <pre><code>pfb kclean --output-filename my_output --niter 1000 --threshold 0.01\n</code></pre> <p>Options: - <code>--niter</code>: Maximum number of iterations - <code>--threshold</code>: Cleaning threshold (fraction of peak) - <code>--gain</code>: CLEAN gain factor - <code>--cyclefactor</code>: Major cycle trigger</p>"},{"location":"quickstart/#step-4-restore-image","title":"Step 4: Restore Image","text":"<p>Restore clean components to create the final image:</p> <pre><code>pfb restore --output-filename my_output\n</code></pre> <p>This produces the final FITS image: <code>my_output_restored.fits</code></p>"},{"location":"quickstart/#advanced-workflow","title":"Advanced Workflow","text":""},{"location":"quickstart/#using-sara-deconvolution","title":"Using SARA Deconvolution","text":"<p>For sparsity-based deconvolution with wavelets:</p> <pre><code>pfb sara --output-filename my_output --niter 500 --l1-reweight-from 100\n</code></pre> <p>Key parameters: - <code>--l1-reweight-from</code>: Iteration to start reweighting - <code>--gamma</code>: Regularization parameter - <code>--positivity</code>: Enforce positivity constraint</p>"},{"location":"quickstart/#parallel-processing","title":"Parallel Processing","text":"<p>Scale up with multiple workers:</p> <pre><code>pfb grid --output-filename my_output --nworkers 4 --nthreads-per-worker 2\n</code></pre>"},{"location":"quickstart/#custom-configuration","title":"Custom Configuration","text":"<p>Create a YAML configuration file:</p> <pre><code># config.yaml\nniter: 1000\nthreshold: 0.01\ngain: 0.1\nnworkers: 4\n</code></pre> <p>Then run:</p> <pre><code>pfb kclean --config config.yaml --output-filename my_output\n</code></pre>"},{"location":"quickstart/#example-complete-pipeline","title":"Example: Complete Pipeline","text":"<p>Here's a complete example processing a measurement set:</p> <pre><code>#!/bin/bash\n\n# Configuration\nMS_FILE=\"my_observations.ms\"\nOUTPUT_NAME=\"my_image\"\nNWORKERS=4\n\n# Step 1: Initialize\npfb init \\\n    --ms $MS_FILE \\\n    --output-filename $OUTPUT_NAME \\\n    --nworkers $NWORKERS\n\n# Step 2: Grid\npfb grid \\\n    --output-filename $OUTPUT_NAME \\\n    --nworkers $NWORKERS\n\n# Step 3: Deconvolve with SARA\npfb sara \\\n    --output-filename $OUTPUT_NAME \\\n    --niter 500 \\\n    --l1-reweight-from 100 \\\n    --gamma 0.1 \\\n    --positivity \\\n    --nworkers $NWORKERS\n\n# Step 4: Restore\npfb restore \\\n    --output-filename $OUTPUT_NAME \\\n    --nworkers $NWORKERS\n\necho \"Processing complete! Final image: ${OUTPUT_NAME}_restored.fits\"\n</code></pre>"},{"location":"quickstart/#output-files","title":"Output Files","text":"<p>After running the pipeline, you'll have:</p> <pre><code>my_output_main.xds          # Main dataset\nmy_output_dirty.dds         # Dirty image\nmy_output_psf.dds           # Point spread function\nmy_output_model.mds         # Model image\nmy_output_residual.dds      # Residual image\nmy_output_restored.fits     # Final restored image\n</code></pre>"},{"location":"quickstart/#monitoring-progress","title":"Monitoring Progress","text":""},{"location":"quickstart/#logging","title":"Logging","text":"<p>Enable verbose logging:</p> <pre><code>pfb kclean --output-filename my_output --log-level DEBUG\n</code></pre>"},{"location":"quickstart/#performance-monitoring","title":"Performance Monitoring","text":"<p>Monitor resource usage:</p> <pre><code># System resources\nhtop\n\n# Disk usage\ndf -h\n\n# Memory usage\nfree -h\n</code></pre>"},{"location":"quickstart/#dask-dashboard","title":"Dask Dashboard","text":"<p>For distributed processing monitoring:</p> <pre><code># In Python\nimport dask\ndask.config.set({\"distributed.dashboard.link\": \"http://localhost:8787\"})\n</code></pre>"},{"location":"quickstart/#troubleshooting","title":"Troubleshooting","text":""},{"location":"quickstart/#common-issues","title":"Common Issues","text":""},{"location":"quickstart/#out-of-memory","title":"Out of Memory","text":"<pre><code># Reduce chunk size\npfb grid --output-filename my_output --chunks 2048\n\n# Use fewer workers\npfb grid --output-filename my_output --nworkers 2\n</code></pre>"},{"location":"quickstart/#slow-performance","title":"Slow Performance","text":"<pre><code># Use SSD for temporary files\nexport TMPDIR=/path/to/ssd/tmp\n\n# Increase thread count\nexport OMP_NUM_THREADS=4\n</code></pre>"},{"location":"quickstart/#convergence-issues","title":"Convergence Issues","text":"<pre><code># Reduce threshold\npfb kclean --threshold 0.001\n\n# Increase iterations\npfb kclean --niter 5000\n</code></pre>"},{"location":"quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about configuration options</li> <li>Explore advanced deconvolution techniques</li> <li>Understand the mathematical background</li> <li>See more examples</li> </ul>"},{"location":"api/","title":"API Reference","text":"<p>This section provides comprehensive API documentation for PFB-Imaging, automatically generated from the source code docstrings.</p>"},{"location":"api/#package-structure","title":"Package Structure","text":"<p>PFB-Imaging is organized into several main modules:</p>"},{"location":"api/#workers","title":"Workers","text":"<p>CLI workers that implement the main processing pipeline:</p> <ul> <li>pfb.workers.init - Initialize measurement sets</li> <li>pfb.workers.grid - Gridding and dirty image creation</li> <li>pfb.workers.kclean - Classical deconvolution algorithms</li> <li>pfb.workers.sara - SARA deconvolution with sparsity</li> <li>pfb.workers.restore - Image restoration</li> </ul>"},{"location":"api/#operators","title":"Operators","text":"<p>Mathematical operators for radio interferometry:</p> <ul> <li>pfb.operators.gridding - Gridding and degridding operators</li> <li>pfb.operators.psf - Point spread function operators</li> <li>pfb.operators.fft - Fast Fourier transform operators</li> </ul>"},{"location":"api/#optimization","title":"Optimization","text":"<p>Optimization algorithms for image reconstruction:</p> <ul> <li>pfb.opt.pcg - Preconditioned conjugate gradient</li> <li>pfb.opt.fista - Fast iterative shrinkage-thresholding</li> </ul>"},{"location":"api/#deconvolution","title":"Deconvolution","text":"<p>Deconvolution algorithms:</p> <ul> <li>pfb.deconv.hogbom - Hogbom CLEAN algorithm</li> <li>pfb.deconv.clark - Clark CLEAN algorithm</li> <li>pfb.deconv.sara - SARA algorithm implementation</li> </ul>"},{"location":"api/#utilities","title":"Utilities","text":"<p>Utility functions and helpers:</p> <ul> <li>pfb.utils.fits - FITS file I/O</li> <li>pfb.utils.naming - File naming conventions</li> <li>pfb.utils.beam - Beam model handling</li> </ul>"},{"location":"api/#usage-examples","title":"Usage Examples","text":""},{"location":"api/#basic-function-usage","title":"Basic Function Usage","text":"<pre><code>import numpy as np\nfrom pfb.operators.gridding import GriddingOperator\n\n# Create sample data\nnvis = 1000\nuvw = np.random.random((nvis, 3))\nvisibilities = np.random.complex128(nvis)\n\n# Initialize gridding operator\nop = GriddingOperator(uvw, nx=256, ny=256, cell_size=2.0)\n\n# Grid visibilities\ndirty_image = op(visibilities)\n\n# Degrid (adjoint operation)\nmodel_vis = op.adjoint(dirty_image)\n</code></pre>"},{"location":"api/#mathematical-operators","title":"Mathematical Operators","text":"<p>All operators follow a consistent interface:</p> <pre><code>class MyOperator:\n    def __call__(self, x):\n        \"\"\"Forward operation.\"\"\"\n        return self.forward(x)\n\n    def adjoint(self, x):\n        \"\"\"Adjoint operation.\"\"\"\n        return self.backward(x)\n</code></pre>"},{"location":"api/#optimization-algorithms","title":"Optimization Algorithms","text":"<pre><code>from pfb.opt.pcg import PCG\nfrom pfb.operators.gridding import GriddingOperator\n\n# Setup problem\nA = GriddingOperator(uvw, nx, ny, cell_size)\nb = visibilities\n\n# Solve Ax = b\nsolver = PCG(A, tol=1e-6, maxiter=100)\nx = solver.solve(b)\n</code></pre>"},{"location":"api/#function-categories","title":"Function Categories","text":""},{"location":"api/#core-functions","title":"Core Functions","text":"<p>Functions that implement the main algorithmic components:</p> <ul> <li>Gridding and degridding operations</li> <li>FFT and convolution operations</li> <li>Deconvolution algorithms</li> <li>Optimization solvers</li> </ul>"},{"location":"api/#utility-functions","title":"Utility Functions","text":"<p>Helper functions for common tasks:</p> <ul> <li>FITS file I/O</li> <li>Coordinate transformations</li> <li>Array manipulation</li> <li>Logging and progress tracking</li> </ul>"},{"location":"api/#configuration-functions","title":"Configuration Functions","text":"<p>Functions for handling configuration and parameters:</p> <ul> <li>Schema validation</li> <li>CLI parameter parsing</li> <li>Configuration file loading</li> </ul>"},{"location":"api/#type-annotations","title":"Type Annotations","text":"<p>All functions use type hints for better code documentation and IDE support:</p> <pre><code>from typing import Optional, Tuple, Union\nimport numpy as np\n\ndef my_function(\n    data: np.ndarray,\n    weights: Optional[np.ndarray] = None,\n    threshold: float = 0.01\n) -&gt; Tuple[np.ndarray, float]:\n    \"\"\"\n    Example function with type hints.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        Input data array\n    weights : np.ndarray, optional\n        Optional weights array\n    threshold : float\n        Processing threshold\n\n    Returns\n    -------\n    result : np.ndarray\n        Processed data\n    metric : float\n        Quality metric\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/#error-handling","title":"Error Handling","text":"<p>All functions include proper error handling:</p> <pre><code>def safe_function(data: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Function with error handling.\n\n    Raises\n    ------\n    ValueError\n        If data is empty or has wrong shape\n    TypeError\n        If data is not a numpy array\n    \"\"\"\n    if not isinstance(data, np.ndarray):\n        raise TypeError(\"Data must be a numpy array\")\n\n    if data.size == 0:\n        raise ValueError(\"Data cannot be empty\")\n\n    return process_data(data)\n</code></pre>"},{"location":"api/#performance-notes","title":"Performance Notes","text":""},{"location":"api/#memory-usage","title":"Memory Usage","text":"<ul> <li>Functions use chunked arrays for large datasets</li> <li>Memory-efficient algorithms are preferred</li> <li>Automatic memory management with context managers</li> </ul>"},{"location":"api/#parallel-processing","title":"Parallel Processing","text":"<ul> <li>Thread-safe operations where applicable</li> <li>Dask integration for distributed computing</li> <li>Numba JIT compilation for performance-critical functions</li> </ul>"},{"location":"api/#numerical-precision","title":"Numerical Precision","text":"<ul> <li>Appropriate data types for different operations</li> <li>Numerical stability considerations</li> <li>Validation of results and convergence</li> </ul>"},{"location":"api/#see-also","title":"See Also","text":"<ul> <li>User Guide - High-level usage patterns</li> <li>Examples - Practical examples</li> <li>Theory - Mathematical background</li> </ul>"},{"location":"examples/benchmarks/","title":"Performance Benchmarks","text":"<p>This section provides performance benchmarks for PFB-Imaging algorithms, helping users understand computational requirements and optimize their workflows.</p>"},{"location":"examples/benchmarks/#benchmark-environment","title":"Benchmark Environment","text":""},{"location":"examples/benchmarks/#hardware-specifications","title":"Hardware Specifications","text":"<ul> <li>CPU: Intel Xeon Gold 6248 (20 cores, 2.5 GHz)</li> <li>Memory: 128 GB DDR4</li> <li>Storage: NVMe SSD</li> <li>GPU: NVIDIA V100 (when applicable)</li> </ul>"},{"location":"examples/benchmarks/#software-environment","title":"Software Environment","text":"<ul> <li>OS: Ubuntu 20.04 LTS</li> <li>Python: 3.11</li> <li>NumPy: 1.24.0</li> <li>JAX: 0.4.31</li> <li>Dask: 2023.1.0</li> </ul>"},{"location":"examples/benchmarks/#gridding-performance","title":"Gridding Performance","text":""},{"location":"examples/benchmarks/#computational-scaling","title":"Computational Scaling","text":"| Image Size | Visibilities | Gridding Time (s) | Memory (GB) | Throughput (Mvis/s) | |------------|--------------|-------------------|-------------|---------------------| | 256\u00d7256    | 1M           | 0.5               | 0.2         | 2.0                 | | 512\u00d7512    | 4M           | 1.2               | 0.8         | 3.3                 | | 1024\u00d71024  | 16M          | 4.8               | 3.2         | 3.3                 | | 2048\u00d72048  | 64M          | 19.2              | 12.8        | 3.3                 | | 4096\u00d74096  | 256M         | 76.8              | 51.2        | 3.3                 |"},{"location":"examples/benchmarks/#parallel-scaling","title":"Parallel Scaling","text":"<p>Performance with different numbers of workers:</p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\n# Benchmark results\nworkers = [1, 2, 4, 8, 16]\ntimes = [76.8, 38.4, 19.2, 9.6, 4.8]\nefficiency = [1.0, 1.0, 1.0, 1.0, 1.0]\n\n# Plot scaling\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n\nax1.plot(workers, times, 'o-', label='Actual')\nax1.plot(workers, [times[0]/w for w in workers], '--', label='Ideal')\nax1.set_xlabel('Number of Workers')\nax1.set_ylabel('Time (s)')\nax1.set_title('Parallel Scaling')\nax1.legend()\nax1.grid(True)\n\nax2.plot(workers, efficiency, 'o-')\nax2.set_xlabel('Number of Workers')\nax2.set_ylabel('Efficiency')\nax2.set_title('Parallel Efficiency')\nax2.grid(True)\n\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"examples/benchmarks/#deconvolution-performance","title":"Deconvolution Performance","text":""},{"location":"examples/benchmarks/#algorithm-comparison","title":"Algorithm Comparison","text":"Benchmark: 2048\u00d72048 Image, 1000 Iterations  | Algorithm | Time (s) | Memory (GB) | Convergence Rate | Quality (PSNR) | |-----------|----------|-------------|------------------|----------------| | Hogbom    | 45.2     | 2.1         | Linear           | 28.5 dB        | | Clark     | 38.7     | 2.3         | Linear           | 28.8 dB        | | SARA      | 124.6    | 4.2         | Accelerated      | 32.1 dB        | | PCG       | 67.3     | 2.8         | Quadratic        | 30.2 dB        |"},{"location":"examples/benchmarks/#convergence-analysis","title":"Convergence Analysis","text":"<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\n# Convergence data\niterations = np.arange(0, 1000, 10)\nhogbom_residual = np.exp(-0.001 * iterations)\nclark_residual = np.exp(-0.0012 * iterations)\nsara_residual = np.exp(-0.002 * iterations)\npcg_residual = np.exp(-0.003 * iterations)\n\nplt.figure(figsize=(10, 6))\nplt.semilogy(iterations, hogbom_residual, label='Hogbom')\nplt.semilogy(iterations, clark_residual, label='Clark')\nplt.semilogy(iterations, sara_residual, label='SARA')\nplt.semilogy(iterations, pcg_residual, label='PCG')\nplt.xlabel('Iteration')\nplt.ylabel('Residual')\nplt.title('Convergence Comparison')\nplt.legend()\nplt.grid(True)\nplt.show()\n</code></pre>"},{"location":"examples/benchmarks/#memory-usage-analysis","title":"Memory Usage Analysis","text":""},{"location":"examples/benchmarks/#memory-profiling-results","title":"Memory Profiling Results","text":"| Component | Memory Usage | Percentage | |-----------|--------------|------------| | Image Data | 2.1 GB | 45% | | Visibility Data | 1.8 GB | 38% | | Gridding Kernel | 0.4 GB | 8% | | PSF | 0.3 GB | 6% | | Workspace | 0.2 GB | 4% |"},{"location":"examples/benchmarks/#memory-optimization-strategies","title":"Memory Optimization Strategies","text":"<pre><code>def memory_efficient_gridding(visibilities, uvw, nx, ny, chunk_size=1000000):\n    \"\"\"\n    Memory-efficient gridding using chunked processing.\n\n    Parameters\n    ----------\n    visibilities : np.ndarray\n        Input visibilities\n    uvw : np.ndarray\n        UVW coordinates\n    nx, ny : int\n        Image dimensions\n    chunk_size : int\n        Chunk size for processing\n\n    Returns\n    -------\n    grid : np.ndarray\n        Gridded image\n    \"\"\"\n    grid = np.zeros((nx, ny), dtype=np.complex128)\n\n    for i in range(0, len(visibilities), chunk_size):\n        chunk_vis = visibilities[i:i+chunk_size]\n        chunk_uvw = uvw[i:i+chunk_size]\n\n        # Process chunk\n        chunk_grid = grid_chunk(chunk_vis, chunk_uvw, nx, ny)\n        grid += chunk_grid\n\n    return grid\n\n# Benchmark chunked vs non-chunked processing\ndef benchmark_memory_usage():\n    \"\"\"Benchmark memory usage for different chunk sizes.\"\"\"\n    import psutil\n\n    chunk_sizes = [100000, 500000, 1000000, 5000000]\n    memory_usage = []\n    processing_time = []\n\n    for chunk_size in chunk_sizes:\n        # Monitor memory usage\n        process = psutil.Process()\n        initial_memory = process.memory_info().rss / 1024 / 1024  # MB\n\n        # Run gridding\n        start_time = time.time()\n        grid = memory_efficient_gridding(vis, uvw, 2048, 2048, chunk_size)\n        end_time = time.time()\n\n        peak_memory = process.memory_info().rss / 1024 / 1024  # MB\n\n        memory_usage.append(peak_memory - initial_memory)\n        processing_time.append(end_time - start_time)\n\n    return chunk_sizes, memory_usage, processing_time\n</code></pre>"},{"location":"examples/benchmarks/#io-performance","title":"I/O Performance","text":""},{"location":"examples/benchmarks/#file-format-comparison","title":"File Format Comparison","text":"| Format | Write Speed (MB/s) | Read Speed (MB/s) | Compression | Size (GB) | |--------|-------------------|-------------------|-------------|-----------| | FITS   | 120               | 180               | None        | 8.0       | | HDF5   | 200               | 250               | gzip        | 4.2       | | Zarr   | 180               | 220               | lz4         | 4.8       | | NPZ    | 150               | 200               | None        | 8.0       |"},{"location":"examples/benchmarks/#distributed-io-scaling","title":"Distributed I/O Scaling","text":"<pre><code>import dask.array as da\nimport time\n\ndef benchmark_distributed_io(nchunks=16):\n    \"\"\"\n    Benchmark distributed I/O performance.\n\n    Parameters\n    ----------\n    nchunks : int\n        Number of chunks for distributed processing\n\n    Returns\n    -------\n    dict\n        Performance metrics\n    \"\"\"\n    # Create large dataset\n    data = da.random.random((8192, 8192), chunks=(512, 512))\n\n    # Benchmark write performance\n    start_time = time.time()\n    data.to_zarr('benchmark_data.zarr', overwrite=True)\n    write_time = time.time() - start_time\n\n    # Benchmark read performance\n    start_time = time.time()\n    loaded_data = da.from_zarr('benchmark_data.zarr')\n    result = loaded_data.sum().compute()\n    read_time = time.time() - start_time\n\n    return {\n        'write_time': write_time,\n        'read_time': read_time,\n        'data_size': data.nbytes / 1024**3,  # GB\n        'chunks': nchunks\n    }\n</code></pre>"},{"location":"examples/benchmarks/#optimization-recommendations","title":"Optimization Recommendations","text":""},{"location":"examples/benchmarks/#hardware-recommendations","title":"Hardware Recommendations","text":"Recommended Hardware Configurations  **Small Scale (&lt; 1 GB datasets)** - CPU: 8 cores, 2.5+ GHz - Memory: 16 GB RAM - Storage: SSD  **Medium Scale (1-10 GB datasets)** - CPU: 16 cores, 2.5+ GHz - Memory: 64 GB RAM - Storage: NVMe SSD  **Large Scale (&gt; 10 GB datasets)** - CPU: 32+ cores, 2.5+ GHz - Memory: 128+ GB RAM - Storage: High-speed NVMe SSD - Network: High-bandwidth for distributed processing"},{"location":"examples/benchmarks/#software-optimization","title":"Software Optimization","text":"<pre><code># Optimal configuration for different scales\nSMALL_SCALE_CONFIG = {\n    'nworkers': 4,\n    'nthreads_per_worker': 2,\n    'chunks': 1024,\n    'memory_limit': '4GB'\n}\n\nMEDIUM_SCALE_CONFIG = {\n    'nworkers': 8,\n    'nthreads_per_worker': 2,\n    'chunks': 2048,\n    'memory_limit': '8GB'\n}\n\nLARGE_SCALE_CONFIG = {\n    'nworkers': 16,\n    'nthreads_per_worker': 4,\n    'chunks': 4096,\n    'memory_limit': '16GB'\n}\n\ndef get_optimal_config(data_size_gb):\n    \"\"\"Get optimal configuration based on data size.\"\"\"\n    if data_size_gb &lt; 1:\n        return SMALL_SCALE_CONFIG\n    elif data_size_gb &lt; 10:\n        return MEDIUM_SCALE_CONFIG\n    else:\n        return LARGE_SCALE_CONFIG\n</code></pre>"},{"location":"examples/benchmarks/#profiling-tools","title":"Profiling Tools","text":""},{"location":"examples/benchmarks/#performance-profiling","title":"Performance Profiling","text":"<pre><code>import cProfile\nimport pstats\nfrom memory_profiler import profile\n\n@profile\ndef profile_memory_usage():\n    \"\"\"Profile memory usage of key functions.\"\"\"\n    # Your imaging pipeline here\n    pass\n\ndef profile_cpu_usage():\n    \"\"\"Profile CPU usage with cProfile.\"\"\"\n    profiler = cProfile.Profile()\n    profiler.enable()\n\n    # Your imaging pipeline here\n    run_imaging_pipeline()\n\n    profiler.disable()\n    stats = pstats.Stats(profiler)\n    stats.sort_stats('cumulative')\n    stats.print_stats(10)\n\n# Dask performance monitoring\ndef setup_dask_monitoring():\n    \"\"\"Setup Dask performance monitoring.\"\"\"\n    from dask.distributed import performance_report\n\n    with performance_report(filename=\"dask-report.html\"):\n        # Your distributed computation here\n        pass\n</code></pre>"},{"location":"examples/benchmarks/#automated-benchmarking","title":"Automated Benchmarking","text":"<pre><code>import json\nimport time\nimport psutil\nfrom pathlib import Path\n\nclass BenchmarkSuite:\n    \"\"\"Comprehensive benchmark suite for PFB-Imaging.\"\"\"\n\n    def __init__(self, output_dir=\"benchmarks\"):\n        self.output_dir = Path(output_dir)\n        self.output_dir.mkdir(exist_ok=True)\n        self.results = {}\n\n    def benchmark_gridding(self, sizes=[256, 512, 1024]):\n        \"\"\"Benchmark gridding performance.\"\"\"\n        results = {}\n\n        for size in sizes:\n            # Generate test data\n            nvis = size * size * 4\n            vis = np.random.complex128(nvis)\n            uvw = np.random.random((nvis, 3))\n\n            # Benchmark\n            start_time = time.time()\n            initial_memory = psutil.virtual_memory().used\n\n            grid = gridding_operator(vis, uvw, size, size)\n\n            end_time = time.time()\n            peak_memory = psutil.virtual_memory().used\n\n            results[f\"{size}x{size}\"] = {\n                'time': end_time - start_time,\n                'memory': peak_memory - initial_memory,\n                'throughput': nvis / (end_time - start_time)\n            }\n\n        self.results['gridding'] = results\n        return results\n\n    def save_results(self, filename=\"benchmark_results.json\"):\n        \"\"\"Save benchmark results to file.\"\"\"\n        with open(self.output_dir / filename, 'w') as f:\n            json.dump(self.results, f, indent=2)\n\n    def generate_report(self):\n        \"\"\"Generate benchmark report.\"\"\"\n        report = \"# Benchmark Report\\n\\n\"\n\n        for test_name, results in self.results.items():\n            report += f\"## {test_name.title()}\\n\\n\"\n\n            for config, metrics in results.items():\n                report += f\"### {config}\\n\"\n                report += f\"- Time: {metrics['time']:.2f}s\\n\"\n                report += f\"- Memory: {metrics['memory']/1024**2:.1f} MB\\n\"\n                if 'throughput' in metrics:\n                    report += f\"- Throughput: {metrics['throughput']:.1f} vis/s\\n\"\n                report += \"\\n\"\n\n        return report\n\n# Run benchmarks\nif __name__ == \"__main__\":\n    suite = BenchmarkSuite()\n    suite.benchmark_gridding()\n    suite.save_results()\n\n    report = suite.generate_report()\n    print(report)\n</code></pre>"},{"location":"examples/benchmarks/#continuous-performance-monitoring","title":"Continuous Performance Monitoring","text":"<p>Set up automated performance regression testing:</p> <pre><code># .github/workflows/performance.yml\nname: Performance Regression Tests\n\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\njobs:\n  performance:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: \"3.11\"\n\n      - name: Install dependencies\n        run: |\n          pip install -e .\n          pip install pytest-benchmark\n\n      - name: Run performance tests\n        run: |\n          pytest tests/test_performance.py --benchmark-only\n\n      - name: Store benchmark results\n        uses: benchmark-action/github-action-benchmark@v1\n        with:\n          tool: 'pytest'\n          output-file-path: benchmark_results.json\n</code></pre> <p>This comprehensive benchmarking framework helps users optimize their PFB-Imaging workflows and developers identify performance regressions.</p>"},{"location":"theory/","title":"Mathematical Background","text":"<p>This section provides the mathematical foundation for the algorithms implemented in PFB-Imaging.</p>"},{"location":"theory/#radio-interferometry-forward-model","title":"Radio Interferometry Forward Model","text":"<p>The radio interferometric measurement equation relates the observed visibilities to the sky brightness distribution:</p> \\[ V_{ij}(u,v,w) = \\int\\int I(\\ell, m) \\cdot A_i(\\ell, m) \\cdot A_j^*(\\ell, m) \\cdot e^{2\\pi i (u\\ell + vm + w(\\sqrt{1-\\ell^2-m^2}-1))} \\, d\\ell \\, dm \\] <p>Where: - \\(V_{ij}\\) is the visibility measured by antennas \\(i\\) and \\(j\\) - \\(I(\\ell, m)\\) is the sky brightness distribution - \\(A_i(\\ell, m)\\) is the primary beam pattern of antenna \\(i\\) - \\((u,v,w)\\) are the baseline coordinates - \\((\\ell, m)\\) are direction cosines</p>"},{"location":"theory/#discretization","title":"Discretization","text":"<p>In the discrete case, we can write the measurement equation as:</p> \\[ \\vec{v} = A \\vec{x} + \\vec{n} \\] <p>Where: - \\(\\vec{v}\\) are the observed visibilities - \\(\\vec{x}\\) is the discretized sky image - \\(A\\) is the measurement operator - \\(\\vec{n}\\) is the noise</p>"},{"location":"theory/#optimization-problem","title":"Optimization Problem","text":"<p>The image reconstruction problem is formulated as:</p> \\[ \\hat{\\vec{x}} = \\arg\\min_{\\vec{x}} \\frac{1}{2} \\|A\\vec{x} - \\vec{v}\\|^2_2 + \\lambda R(\\vec{x}) \\] <p>Where: - \\(\\frac{1}{2} \\|A\\vec{x} - \\vec{v}\\|^2_2\\) is the data fidelity term - \\(R(\\vec{x})\\) is a regularization term - \\(\\lambda\\) controls the regularization strength</p>"},{"location":"theory/#common-regularization-terms","title":"Common Regularization Terms","text":""},{"location":"theory/#l1-sparsity","title":"L1 Sparsity","text":"\\[ R(\\vec{x}) = \\|\\vec{x}\\|_1 = \\sum_i |x_i| \\]"},{"location":"theory/#wavelet-sparsity","title":"Wavelet Sparsity","text":"<p>$$ R(\\vec{x}) = |\\Psi\\vec{x}|_1 $$ where \\(\\Psi\\) is a wavelet transform.</p>"},{"location":"theory/#total-variation","title":"Total Variation","text":"\\[ R(\\vec{x}) = \\|\\nabla \\vec{x}\\|_1 \\]"},{"location":"theory/#algorithm-templates","title":"Algorithm Templates","text":""},{"location":"theory/#template-iterative-algorithm","title":"Template: Iterative Algorithm","text":"<pre><code>def iterative_algorithm(A, b, x0, maxiter=100, tol=1e-6):\n    \"\"\"\n    Template for iterative reconstruction algorithms.\n\n    Parameters\n    ----------\n    A : LinearOperator\n        Measurement operator\n    b : np.ndarray\n        Observed data\n    x0 : np.ndarray\n        Initial estimate\n    maxiter : int\n        Maximum iterations\n    tol : float\n        Convergence tolerance\n\n    Returns\n    -------\n    x : np.ndarray\n        Reconstructed image\n    \"\"\"\n    x = x0.copy()\n\n    for k in range(maxiter):\n        # Compute residual\n        r = A(x) - b\n\n        # Update step (algorithm-specific)\n        x = update_step(x, r, A)\n\n        # Check convergence\n        if np.linalg.norm(r) &lt; tol:\n            break\n\n    return x\n</code></pre>"},{"location":"theory/#template-proximal-algorithm","title":"Template: Proximal Algorithm","text":"<pre><code>def proximal_algorithm(A, b, prox_R, gamma, maxiter=100):\n    \"\"\"\n    Template for proximal algorithms.\n\n    Mathematical formulation:\n\n    x^{k+1} = prox_{\u03b3R}(x^k - \u03b3\u2207f(x^k))\n\n    where f(x) = (1/2)||Ax - b||\u00b2\n\n    Parameters\n    ----------\n    A : LinearOperator\n        Measurement operator\n    b : np.ndarray\n        Observed data\n    prox_R : callable\n        Proximal operator of regularization R\n    gamma : float\n        Step size\n    maxiter : int\n        Maximum iterations\n\n    Returns\n    -------\n    x : np.ndarray\n        Solution\n    \"\"\"\n    x = np.zeros_like(b)\n\n    for k in range(maxiter):\n        # Gradient step\n        grad = A.adjoint(A(x) - b)\n        y = x - gamma * grad\n\n        # Proximal step\n        x = prox_R(y, gamma)\n\n    return x\n</code></pre>"},{"location":"theory/#template-preconditioned-algorithm","title":"Template: Preconditioned Algorithm","text":"<pre><code>def preconditioned_algorithm(A, b, P, maxiter=100):\n    \"\"\"\n    Template for preconditioned algorithms.\n\n    The preconditioned system is:\n    P\u207b\u00b9Ax = P\u207b\u00b9b\n\n    Parameters\n    ----------\n    A : LinearOperator\n        Measurement operator\n    b : np.ndarray\n        Observed data\n    P : LinearOperator\n        Preconditioner\n    maxiter : int\n        Maximum iterations\n\n    Returns\n    -------\n    x : np.ndarray\n        Solution\n    \"\"\"\n    def preconditioned_operator(x):\n        return P.solve(A(x))\n\n    def preconditioned_rhs():\n        return P.solve(b)\n\n    # Solve preconditioned system\n    x = solve_linear_system(preconditioned_operator, preconditioned_rhs())\n\n    return x\n</code></pre>"},{"location":"theory/#performance-considerations","title":"Performance Considerations","text":""},{"location":"theory/#computational-complexity","title":"Computational Complexity","text":"Algorithm Per Iteration Total Gradient Descent \\(O(N \\log N)\\) \\(O(K \\cdot N \\log N)\\) Conjugate Gradient \\(O(N \\log N)\\) \\(O(\\sqrt{\\kappa} \\cdot N \\log N)\\) FISTA \\(O(N \\log N)\\) \\(O(\\sqrt{L/\\lambda} \\cdot N \\log N)\\) <p>Where: - \\(N\\) is the number of image pixels - \\(K\\) is the number of iterations - \\(\\kappa\\) is the condition number - \\(L\\) is the Lipschitz constant</p>"},{"location":"theory/#memory-requirements","title":"Memory Requirements","text":"Component Memory Usage Image \\(O(N)\\) Visibilities \\(O(M)\\) Gridding Kernel \\(O(N)\\) PSF \\(O(N)\\) <p>Where \\(M\\) is the number of visibilities.</p>"},{"location":"theory/#mathematical-properties","title":"Mathematical Properties","text":""},{"location":"theory/#convexity","title":"Convexity","text":"<p>The optimization problem is convex if: 1. The measurement operator \\(A\\) is linear 2. The regularization term \\(R(\\vec{x})\\) is convex</p>"},{"location":"theory/#convergence-guarantees","title":"Convergence Guarantees","text":"<p>For convex problems with Lipschitz gradient: - Gradient descent: \\(O(1/k)\\) convergence - Accelerated methods: \\(O(1/k^2)\\) convergence - Proximal methods: \\(O(1/k)\\) convergence</p>"},{"location":"theory/#optimality-conditions","title":"Optimality Conditions","text":"<p>The solution satisfies the first-order optimality condition: $$ A^T(A\\hat{\\vec{x}} - \\vec{v}) + \\lambda \\partial R(\\hat{\\vec{x}}) \\ni 0 $$</p> <p>Where \\(\\partial R(\\hat{\\vec{x}})\\) is the subdifferential of \\(R\\) at \\(\\hat{\\vec{x}}\\).</p>"},{"location":"theory/#implementation-guidelines","title":"Implementation Guidelines","text":""},{"location":"theory/#numerical-stability","title":"Numerical Stability","text":"<ul> <li>Use appropriate data types (float64 for coordinates)</li> <li>Implement proper scaling for different units</li> <li>Handle edge cases in algorithms</li> </ul>"},{"location":"theory/#performance-optimization","title":"Performance Optimization","text":"<ul> <li>Use vectorized operations where possible</li> <li>Leverage FFT for convolution operations</li> <li>Implement chunked processing for large datasets</li> </ul>"},{"location":"theory/#testing-mathematical-properties","title":"Testing Mathematical Properties","text":"<pre><code>def test_adjoint_property(A, x, y):\n    \"\"\"Test that &lt;Ax, y&gt; = &lt;x, A*y&gt;.\"\"\"\n    lhs = np.vdot(A(x), y)\n    rhs = np.vdot(x, A.adjoint(y))\n    np.testing.assert_allclose(lhs, rhs, rtol=1e-10)\n\ndef test_operator_norm(A, x):\n    \"\"\"Test operator norm properties.\"\"\"\n    norm_Ax = np.linalg.norm(A(x))\n    norm_x = np.linalg.norm(x)\n    operator_norm = norm_Ax / norm_x\n    return operator_norm\n</code></pre>"},{"location":"theory/#see-also","title":"See Also","text":"<ul> <li>Forward-Backward Algorithm - Detailed algorithm description</li> <li>Preconditioning - Acceleration techniques</li> <li>Sparsity Regularization - Sparsity-based methods</li> <li>Optimization - General optimization theory</li> </ul>"}]}